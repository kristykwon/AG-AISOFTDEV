{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 12:37:13,324 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 12:37:17,140 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Enhanced prompt\n",
      " <persona>\n",
      "You are a Senior Database Architect with extensive experience designing highly-normalized, production-grade relational schemas.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Below is the complete Product Requirements Document (PRD) for “WelcomePath: New Hire Onboarding Platform.”  \n",
      "Use it as the authoritative source for functional scope and data entities.\n",
      "\n",
      "--- PRD START ---\n",
      "# Product Requirements Document: WelcomePath: New Hire Onboarding Platform\n",
      "| Status | **Draft** |\n",
      "| **Author** | Product Team Alpha |\n",
      "| **Version** | 1.0 |\n",
      "| **Last Updated** | 2023-10-27 |\n",
      "[ full PRD content exactly as supplied by the user ]\n",
      "--- PRD END ---\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step by step to identify every core entity, relationship, and attribute required to satisfy the PRD’s Version 1.0 scope (Stories 1.1, 2.1, 3.1).  \n",
      "2. Apply 3rd-Normal-Form design principles.  \n",
      "3. Create a minimum of two tables—users and onboarding_tasks—then add any additional tables or junction tables necessary for data integrity and efficient querying (e.g., task_templates, roles, user_roles, task_assignments).  \n",
      "4. Specify:\n",
      "   • Appropriate column names and SQL data types (use PostgreSQL syntax).  \n",
      "   • PRIMARY KEY constraints (use SERIAL or BIGSERIAL for surrogate keys).  \n",
      "   • FOREIGN KEY constraints with ON DELETE/UPDATE CASCADE where logical.  \n",
      "   • UNIQUE, NOT NULL, DEFAULT, and CHECK constraints that enforce business rules (e.g., enumerated status values).  \n",
      "5. Do NOT include sample data, comments, or explanatory text—only the raw CREATE TABLE statements.  \n",
      "6. Wrap the entire schema in a single fenced code block annotated with “sql”.  \n",
      "7. Output nothing except that code block.  \n",
      "8. Save the exact contents of the code block to artifacts/schema.sql.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "```sql\n",
      "-- your CREATE TABLE statements here\n",
      "```\n",
      "</output_format>\n",
      "CREATE TABLE users (\n",
      "    user_id SERIAL PRIMARY KEY,\n",
      "    first_name VARCHAR(50) NOT NULL,\n",
      "    last_name VARCHAR(50) NOT NULL,\n",
      "    email VARCHAR(100) NOT NULL UNIQUE,\n",
      "    role_id INT NOT NULL,\n",
      "    start_date DATE NOT NULL,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE roles (\n",
      "    role_id SERIAL PRIMARY KEY,\n",
      "    role_name VARCHAR(50) NOT NULL UNIQUE\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_tasks (\n",
      "    task_id SERIAL PRIMARY KEY,\n",
      "    task_name VARCHAR(100) NOT NULL,\n",
      "    description TEXT,\n",
      "    is_mandatory BOOLEAN NOT NULL DEFAULT TRUE,\n",
      "    status VARCHAR(20) NOT NULL CHECK (status IN ('pending', 'in_progress', 'completed'))\n",
      ");\n",
      "\n",
      "CREATE TABLE task_templates (\n",
      "    template_id SERIAL PRIMARY KEY,\n",
      "    task_id INT NOT NULL,\n",
      "    role_id INT NOT NULL,\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks(task_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE,\n",
      "    UNIQUE (task_id, role_id)\n",
      ");\n",
      "\n",
      "CREATE TABLE user_roles (\n",
      "    user_id INT NOT NULL,\n",
      "    role_id INT NOT NULL,\n",
      "    PRIMARY KEY (user_id, role_id),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE task_assignments (\n",
      "    assignment_id SERIAL PRIMARY KEY,\n",
      "    user_id INT NOT NULL,\n",
      "    task_id INT NOT NULL,\n",
      "    assigned_date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
      "    due_date DATE,\n",
      "    completion_date DATE,\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks(task_id) ON DELETE CASCADE,\n",
      "    UNIQUE (user_id, task_id)\n",
      ");\n",
      "CREATE TABLE users (\n",
      "    user_id SERIAL PRIMARY KEY,\n",
      "    first_name VARCHAR(50) NOT NULL,\n",
      "    last_name VARCHAR(50) NOT NULL,\n",
      "    email VARCHAR(100) NOT NULL UNIQUE,\n",
      "    role_id INT NOT NULL,\n",
      "    start_date DATE NOT NULL,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE roles (\n",
      "    role_id SERIAL PRIMARY KEY,\n",
      "    role_name VARCHAR(50) NOT NULL UNIQUE\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_tasks (\n",
      "    task_id SERIAL PRIMARY KEY,\n",
      "    task_name VARCHAR(100) NOT NULL,\n",
      "    description TEXT,\n",
      "    is_mandatory BOOLEAN NOT NULL DEFAULT TRUE,\n",
      "    status VARCHAR(20) NOT NULL CHECK (status IN ('pending', 'in_progress', 'completed'))\n",
      ");\n",
      "\n",
      "CREATE TABLE task_templates (\n",
      "    template_id SERIAL PRIMARY KEY,\n",
      "    task_id INT NOT NULL,\n",
      "    role_id INT NOT NULL,\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks(task_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE,\n",
      "    UNIQUE (task_id, role_id)\n",
      ");\n",
      "\n",
      "CREATE TABLE user_roles (\n",
      "    user_id INT NOT NULL,\n",
      "    role_id INT NOT NULL,\n",
      "    PRIMARY KEY (user_id, role_id),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE task_assignments (\n",
      "    assignment_id SERIAL PRIMARY KEY,\n",
      "    user_id INT NOT NULL,\n",
      "    task_id INT NOT NULL,\n",
      "    assigned_date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
      "    due_date DATE,\n",
      "    completion_date DATE,\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks(task_id) ON DELETE CASCADE,\n",
      "    UNIQUE (user_id, task_id)\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# TWrite a prompt to generate the SQL schema from the PRD.\n",
    "schema_prompt = f\"\"\"\n",
    "You are a Database Administrator (DBA). \n",
    "\n",
    "Based on the following markdown PRD content, generate a SQL schema \n",
    "for a relational database. \n",
    "\n",
    "<prd_content>\n",
    "{prd_content}\n",
    "</prd_content>\n",
    "\n",
    "Design a normalized SQL schema with at least two tables (e.g.: users and\n",
    "onboarding_tasks):\n",
    "- The 'users' table should include an id, name, email, and role\n",
    "(e.g.: 'New Hire', 'Manager').\n",
    "- The 'onboarding_tasks' table should include an id, a title,\n",
    "a description, a due_date, status, (e.g.: 'Pending', 'Completed'), and\n",
    "a user_id foreign key.\n",
    "\n",
    " Include appropriate fields, data types, primary keys,\n",
    "and foreign keys. Ensure the schema supports efficient querying and data \n",
    "integrity. Provide the SQL schema in a code block without any \n",
    "additional explanation.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- Output should be the raw CREATE TABLE statements in a single \n",
    "SQL code block.\n",
    "- Save the generated SQL to artifacts/schema.sql.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "    print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "    generated_schema = get_completion(enhanced_schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql', overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 12:38:39,994 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed Data Enhanced prompt\n",
      " <prompt>\n",
      "  <persona>\n",
      "    You are a Senior Data Engineer who specializes in seeding relational databases for green-field SaaS applications. You have deep knowledge of SQL, foreign-key integrity, and realistic data modeling for HR and onboarding platforms.\n",
      "  </persona>\n",
      "\n",
      "  <context>\n",
      "    Product: “WelcomePath” — a new-hire onboarding web application.  \n",
      "    Goal: Seed the development database with believable starter data that matches both the PRD vision (digital paperwork, task checklists, role-based templates, etc.) and the SQL schema below.\n",
      "\n",
      "    ---  PRD Highlights  ---\n",
      "    • New-hire personas: Alex Chen (Engineer), etc.  \n",
      "    • Core tasks: “Complete HR Paperwork”, “Schedule 1:1 with Manager”, “Meet Your Team”, etc.  \n",
      "    • Roles: New Hire, Hiring Manager, HR Admin, IT.  \n",
      "    • Mandatory tasks should default to TRUE; status should start as ‘pending’.  \n",
      "    • Dates should be plausible (e.g., start_date within the next 30 days).\n",
      "\n",
      "    ---  SQL Schema (abridged)  ---\n",
      "    roles(role_id, role_name)  \n",
      "    users(user_id, first_name, last_name, email, role_id, start_date)  \n",
      "    onboarding_tasks(task_id, task_name, description, is_mandatory, status)  \n",
      "    task_templates(template_id, task_id, role_id)  \n",
      "    user_roles(user_id, role_id)          -- allows additional roles  \n",
      "    task_assignments(assignment_id, user_id, task_id, assigned_date, due_date, completion_date)\n",
      "\n",
      "    Key constraints:\n",
      "    • role_id in users references roles.  \n",
      "    • task_id/role_id pairs in task_templates are UNIQUE.  \n",
      "    • (user_id, task_id) pairs in task_assignments are UNIQUE.  \n",
      "    • Maintain referential integrity (insert parent rows before child rows).\n",
      "\n",
      "  </context>\n",
      "\n",
      "  <instructions>\n",
      "    1. Think step-by-step to decide:\n",
      "       a. Which 3-4 roles to insert (e.g., ‘Engineer’, ‘Hiring Manager’, ‘HR Admin’, ‘IT Support’).  \n",
      "       b. Which 3-4 users (use realistic names & corporate emails) and map each to exactly one primary role in “users”.  \n",
      "       c. 4-6 onboarding_tasks that align with the PRD (e.g., “Complete HR Paperwork”, “Setup Laptop”, etc.).  \n",
      "       d. Map tasks to roles in task_templates (at least one task per role).  \n",
      "       e. Assign a subset of tasks to one sample new hire in task_assignments, using sensible due_date and NULL completion_date.\n",
      "    2. Generate 5-10 INSERT statements total (multi-row syntax is allowed) that collectively populate ALL SIX tables while satisfying FK & UNIQUE constraints.\n",
      "    3. Use explicit column lists in every INSERT.\n",
      "    4. Wrap literal strings in single quotes, dates in ISO ‘YYYY-MM-DD’.\n",
      "    5. After reasoning, output ONLY the raw SQL INSERT statements—no explanations.\n",
      "    6. Save the same SQL text to artifacts/seed_data.sql (handled by runtime; you only need to output the SQL).\n",
      "\n",
      "    NOTE: Do NOT reveal your internal reasoning; produce only the final SQL.\n",
      "  </instructions>\n",
      "\n",
      "  <examples>\n",
      "    <!-- Minimal illustrative pattern; IDs are auto-assigned so omit them when SERIAL -->\n",
      "    Example (roles):\n",
      "      INSERT INTO roles (role_name) VALUES\n",
      "        ('Engineer'),\n",
      "        ('Hiring Manager');\n",
      "  </examples>\n",
      "\n",
      "  <output_format>\n",
      "    Plain text consisting solely of valid PostgreSQL INSERT statements.\n",
      "  </output_format>\n",
      "</prompt>\n",
      "INSERT INTO roles (role_name) VALUES\n",
      "  ('Engineer'),\n",
      "  ('Hiring Manager'),\n",
      "  ('HR Admin'),\n",
      "  ('IT Support');\n",
      "\n",
      "INSERT INTO users (first_name, last_name, email, role_id, start_date) VALUES\n",
      "  ('Alex', 'Chen', 'alex.chen@welcomepath.com', 1, '2023-11-15'),\n",
      "  ('Morgan', 'Smith', 'morgan.smith@welcomepath.com', 2, '2023-11-10'),\n",
      "  ('Jamie', 'Taylor', 'jamie.taylor@welcomepath.com', 3, '2023-11-20'),\n",
      "  ('Riley', 'Jordan', 'riley.jordan@welcomepath.com', 4, '2023-11-25');\n",
      "\n",
      "INSERT INTO onboarding_tasks (task_name, description, is_mandatory, status) VALUES\n",
      "  ('Complete HR Paperwork', 'Fill out all necessary HR documentation', TRUE, 'pending'),\n",
      "  ('Schedule 1:1 with Manager', 'Set a time to meet your manager', TRUE, 'pending'),\n",
      "  ('Meet Your Team', 'Attend a team meeting', TRUE, 'pending'),\n",
      "  ('Setup Laptop', 'Configure your new laptop with IT support', TRUE, 'pending'),\n",
      "  ('Complete Security Training', 'Finish the mandatory security training course', TRUE, 'pending');\n",
      "\n",
      "INSERT INTO task_templates (task_id, role_id) VALUES\n",
      "  (1, 1),\n",
      "  (2, 2),\n",
      "  (3, 1),\n",
      "  (4, 4),\n",
      "  (5, 3);\n",
      "\n",
      "INSERT INTO task_assignments (user_id, task_id, assigned_date, due_date, completion_date) VALUES\n",
      "  (1, 1, '2023-11-01', '2023-11-08', NULL),\n",
      "  (1, 2, '2023-11-01', '2023-11-09', NULL),\n",
      "  (1, 3, '2023-11-01', '2023-11-10', NULL),\n",
      "  (1, 4, '2023-11-01', '2023-11-11', NULL);\n",
      "INSERT INTO roles (role_name) VALUES\n",
      "  ('Engineer'),\n",
      "  ('Hiring Manager'),\n",
      "  ('HR Admin'),\n",
      "  ('IT Support');\n",
      "\n",
      "INSERT INTO users (first_name, last_name, email, role_id, start_date) VALUES\n",
      "  ('Alex', 'Chen', 'alex.chen@welcomepath.com', 1, '2023-11-15'),\n",
      "  ('Morgan', 'Smith', 'morgan.smith@welcomepath.com', 2, '2023-11-10'),\n",
      "  ('Jamie', 'Taylor', 'jamie.taylor@welcomepath.com', 3, '2023-11-20'),\n",
      "  ('Riley', 'Jordan', 'riley.jordan@welcomepath.com', 4, '2023-11-25');\n",
      "\n",
      "INSERT INTO onboarding_tasks (task_name, description, is_mandatory, status) VALUES\n",
      "  ('Complete HR Paperwork', 'Fill out all necessary HR documentation', TRUE, 'pending'),\n",
      "  ('Schedule 1:1 with Manager', 'Set a time to meet your manager', TRUE, 'pending'),\n",
      "  ('Meet Your Team', 'Attend a team meeting', TRUE, 'pending'),\n",
      "  ('Setup Laptop', 'Configure your new laptop with IT support', TRUE, 'pending'),\n",
      "  ('Complete Security Training', 'Finish the mandatory security training course', TRUE, 'pending');\n",
      "\n",
      "INSERT INTO task_templates (task_id, role_id) VALUES\n",
      "  (1, 1),\n",
      "  (2, 2),\n",
      "  (3, 1),\n",
      "  (4, 4),\n",
      "  (5, 3);\n",
      "\n",
      "INSERT INTO task_assignments (user_id, task_id, assigned_date, due_date, completion_date) VALUES\n",
      "  (1, 1, '2023-11-01', '2023-11-08', NULL),\n",
      "  (1, 2, '2023-11-01', '2023-11-09', NULL),\n",
      "  (1, 3, '2023-11-01', '2023-11-10', NULL),\n",
      "  (1, 4, '2023-11-01', '2023-11-11', NULL);\n"
     ]
    }
   ],
   "source": [
    "# TWrite a prompt to generate realistic seed data.\n",
    "seed_data_prompt = f\"\"\"\n",
    "You are a data specialist. Based on the PRD and cleaned SQL \n",
    "schema provided, generate 5 to 10 realistic INSERT statements to populate \n",
    "the database tables with data relevant to a new hire onboarding tool \n",
    "(e.g., sample user names and tasks like \"Complete HR Paperwork\").\n",
    "\n",
    "**PRD CONTENT**:\n",
    "<prd_content>\n",
    "{prd_content}\n",
    "</prd_content> \n",
    "\n",
    "**SQL SCHEMA**:\n",
    "<cleaned_schema>\n",
    "{cleaned_schema}\n",
    "</cleaned_schema>\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- Output only the raw 'SQL' INSERT statements.\n",
    "- Save the generated INSERT statements to artifacts/seed_data.sql.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    enhanced_seed_data_prompt = prompt_enhancer(seed_data_prompt)\n",
    "    print(\"Seed Data Enhanced prompt\\n\", enhanced_seed_data_prompt)\n",
    "    generated_seed_data = get_completion(enhanced_seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing database file at c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\onboarding.db\n",
      "Successfully connected to database at c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\onboarding.db\n",
      "Tables created successfully.\n",
      "Seed data executed successfully.\n",
      "Database changes committed.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\n",
    "\n",
    "    This function is defensive: it validates that the schema/seed files\n",
    "    contain SQL-like content before attempting to execute them. It uses\n",
    "    executescript() for multi-statement SQL and always closes the DB\n",
    "    connection in the finally block.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "\n",
    "    # Delete database file if it exists to start fresh\n",
    "    if os.path.exists(db_path):\n",
    "        try:\n",
    "            os.remove(db_path)\n",
    "            print(f\"Removed existing database file at {db_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not remove existing db file: {e}\")\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        # Connect (creates file if missing)\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read the schema SQL from disk\n",
    "        try:\n",
    "            with open(schema_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                schema_sql = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading schema file: {e}\")\n",
    "            return\n",
    "\n",
    "        if not schema_sql.strip():\n",
    "            print(f\"Warning: Schema file {schema_path} is empty. No tables created.\")\n",
    "            return\n",
    "\n",
    "        # Quick sanity check: ensure the content looks like SQL (contains CREATE TABLE)\n",
    "        if \"create table\" not in schema_sql.lower():\n",
    "            preview = schema_sql.strip()[:200].replace(\"\\n\", \" \")\n",
    "            print(\"Schema file does not look like valid SQL. Aborting execution.\")\n",
    "            print(\"Schema preview:\", preview)\n",
    "            return\n",
    "\n",
    "        # Execute the schema SQL (multi-statement)\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # If seed file exists, read and execute it\n",
    "        if os.path.exists(seed_path):\n",
    "            try:\n",
    "                with open(seed_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    seed_sql = f.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading seed file: {e}\")\n",
    "                seed_sql = \"\"\n",
    "\n",
    "            if seed_sql.strip():\n",
    "                # Use executescript to allow multiple INSERT statements\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data executed successfully.\")\n",
    "            else:\n",
    "                print(f\"Warning: Seed file {seed_path} is empty. No seed data applied.\")\n",
    "        else:\n",
    "            print(f\"No seed file found at {seed_path}; skipping seed step.\")\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Rolled back changes due to error.\")\n",
    "    finally:\n",
    "        # Ensure the connection is closed\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
