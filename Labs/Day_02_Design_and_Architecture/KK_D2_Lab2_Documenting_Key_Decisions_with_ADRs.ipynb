{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 13:11:48,654 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 14:12:44,743 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_adr_template_prompt: <persona>\n",
      "You are a Senior Technical Documentation Engineer with deep expertise in software-architecture artifacts and markdown authoring best practices.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Architectural Decision Records (ADRs) capture important architectural choices made during a project.  \n",
      "This ADR template must be:\n",
      "• Clean and reusable (i.e., written once, copied many times).  \n",
      "• Markdown-compliant so that any renderer (GitHub, GitLab, static-site generators) displays it correctly.  \n",
      "• Saved under the relative path templates/adr_template.md inside the repository.  \n",
      "Required template sections (in order):\n",
      "1. Title – a short, descriptive heading (placeholder only).  \n",
      "2. Status – allowed values: Proposed, Accepted, Deprecated (placeholder only).  \n",
      "3. Context – bulleted list describing driving forces (placeholder bullets).  \n",
      "4. Decision – concise statement of the chosen solution (placeholder).  \n",
      "5. Consequences – bulleted list of positive and negative results (placeholder bullets).  \n",
      "All placeholders must be clearly indicated with angle-bracketed labels (e.g., `<TITLE>`).\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "Think step by step to ensure:\n",
      "1. Every mandatory section is present and correctly ordered.  \n",
      "2. Each placeholder is easy to replace in future ADRs.  \n",
      "3. The output is wrapped in a markdown code fence and prefixed by the path line exactly as shown in the output specification.\n",
      "Then generate the template.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "Return ONLY the following two items, nothing else:\n",
      "1. A single line: Path: templates/adr_template.md  \n",
      "2. Immediately after that line, a markdown code fence (```markdown … ```), containing the complete ADR template.\n",
      "\n",
      "Example (structure only; substitute with finished template):\n",
      "\n",
      "Path: templates/adr_template.md\n",
      "```markdown\n",
      "# <TITLE>\n",
      "Status: <STATUS>\n",
      "\n",
      "## Context\n",
      "* <CONTEXT_POINT_1>\n",
      "* …\n",
      "\n",
      "## Decision\n",
      "<DECISION_STATEMENT>\n",
      "\n",
      "## Consequences\n",
      "* <CONSEQUENCE_POSITIVE_1>\n",
      "* <CONSEQUENCE_NEGATIVE_1>\n",
      "```\n",
      "\n",
      "Follow this exact format.\n",
      "</output_format>\n",
      "Path: templates/adr_template.md\n",
      "```markdown\n",
      "# <TITLE>\n",
      "Status: <STATUS>\n",
      "\n",
      "## Context\n",
      "* <CONTEXT_POINT_1>\n",
      "* <CONTEXT_POINT_2>\n",
      "* <CONTEXT_POINT_3>\n",
      "\n",
      "## Decision\n",
      "<DECISION_STATEMENT>\n",
      "\n",
      "## Consequences\n",
      "* <CONSEQUENCE_POSITIVE_1>\n",
      "* <CONSEQUENCE_NEGATIVE_1>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# TWrite a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\" \n",
    "You are a data specialist. Generate a clean, reusable markdown \n",
    "template for an Architectural Decision Record (ADR) that includes \n",
    "tne following sections:\n",
    "1. Title: \n",
    "- [A short, descriptive title]\n",
    "2. Status: \n",
    "- [Proposed, Accepted, Deprecated]\n",
    "3. Context:\n",
    "- [Through a list format, describe the problem or forces at play]\n",
    "4. Decision:\n",
    "- [State the chosen solution clearly and concisely]\n",
    "5. Consequences:\n",
    "- [List the positive and negative results of the decision]\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- Save the generated template to templates/adr_template.md\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "enhanced_adr_template_prompt = prompt_enhancer(adr_template_prompt)\n",
    "print(\"enhanced_adr_template_prompt:\", enhanced_adr_template_prompt)\n",
    "adr_template_content = get_completion(enhanced_adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\",\n",
    "                  overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 14:14:53,040 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_db_research_prompt: <prompt>\n",
      "    <persona>\n",
      "        You are a senior database solutions architect with expertise in both traditional relational databases (e.g., PostgreSQL) and purpose-built vector search engines (e.g., FAISS, ChromaDB, Milvus). Your recommendations must be technically accurate, balanced, and suitable for a software-engineering audience that will use them to choose an architecture for a new-hire onboarding tool.\n",
      "    </persona>\n",
      "\n",
      "    <context>\n",
      "        The engineering team is evaluating two ways to store and query vector embeddings generated from onboarding documents, training videos, and FAQ content:\n",
      "\n",
      "        • Approach 1 – “PostgreSQL + pgvector”:  \n",
      "          Store embeddings in a standard PostgreSQL cluster that has the pgvector extension enabled.  \n",
      "        • Approach 2 – “Dedicated Vector DB (e.g., FAISS, ChromaDB)”:  \n",
      "          Store embeddings in a purpose-built vector database or engine designed specifically for similarity search.\n",
      "\n",
      "        Key evaluation dimensions include—but are not limited to—performance, scalability, operational complexity, ecosystem/tooling, total cost of ownership (TCO), security/compliance, and future extensibility.\n",
      "\n",
      "        Definitions  \n",
      "        • Vector embedding: A high-dimensional numeric representation of text or other data used for similarity search.  \n",
      "        • pgvector: A PostgreSQL extension that adds a custom column type and index methods for vector similarity.  \n",
      "        • FAISS/ChromaDB: Specialized libraries or databases optimized for high-performance vector similarity search.\n",
      "    </context>\n",
      "\n",
      "    <instructions>\n",
      "        1. Think step by step and perform any necessary intermediate reasoning internally before writing the final answer. Do NOT reveal the private reasoning chain.  \n",
      "        2. Produce a clear, balanced “Pros vs. Cons” comparison for each approach across the evaluation dimensions listed in the context (and any additional dimensions you deem relevant).  \n",
      "        3. Be concise but technically thorough; focus on facts over opinions.  \n",
      "        4. Cite specific PostgreSQL features (e.g., extensions, indexing methods), and name at least two concrete vector-DB solutions (e.g., FAISS, ChromaDB) when applicable.  \n",
      "        5. Avoid marketing language; stay objective and engineering-oriented.\n",
      "    </instructions>\n",
      "\n",
      "    <output_format>\n",
      "        Return a single JSON object assigned to the variable name db_research_output.  \n",
      "        The JSON schema must be:\n",
      "\n",
      "        {\n",
      "          \"approach_1\": {\n",
      "            \"pros\": [\"...\",\"...\"],\n",
      "            \"cons\": [\"...\",\"...\"]\n",
      "          },\n",
      "          \"approach_2\": {\n",
      "            \"pros\": [\"...\",\"...\"],\n",
      "            \"cons\": [\"...\",\"...\"]\n",
      "          }\n",
      "        }\n",
      "\n",
      "        • Use short, declarative bullet sentences inside each list.  \n",
      "        • Maximum 6 bullets in each pros/cons list.  \n",
      "        • No additional keys, narrative text, or code fencing—only the variable assignment followed by the JSON object.\n",
      "    </output_format>\n",
      "</prompt>\n",
      "```python\n",
      "db_research_output = \"\"\"\n",
      "# Comparison of Database Options for New Hire Onboarding Tool\n",
      "\n",
      "## Approach 1: Using PostgreSQL with the pgvector extension\n",
      "\n",
      "### Pros:\n",
      "1. **Familiarity and Integration**: PostgreSQL is a widely used relational database, likely familiar to the team. It integrates seamlessly with existing systems that use PostgreSQL, reducing the learning curve and integration effort.\n",
      "2. **ACID Compliance**: Provides strong transactional support, ensuring data consistency and reliability which can be critical for onboarding data.\n",
      "3. **Flexibility**: Allows for both relational and vector data storage, making it a versatile choice if both types of data are needed.\n",
      "4. **Single System**: Using a single database system for both relational and vector data can simplify system architecture and maintenance.\n",
      "5. **Community and Support**: PostgreSQL has a large community and extensive documentation, which can aid in troubleshooting and optimizing its use.\n",
      "\n",
      "### Cons:\n",
      "1. **Performance**: While pgvector allows for vector operations, it may not be as optimized for high-dimensional vector searches as specialized vector databases, potentially leading to slower query performance in large-scale applications.\n",
      "2. **Scalability**: As data size grows, PostgreSQL may face challenges in efficiently handling high-dimensional vector queries compared to specialized solutions.\n",
      "3. **Feature Set**: pgvector may lack some advanced features and optimizations present in dedicated vector databases, such as specific indexing and search algorithms.\n",
      "\n",
      "## Approach 2: Using a Specialized Vector Database (e.g., ChromaDB or FAISS)\n",
      "\n",
      "### Pros:\n",
      "1. **Performance Optimization**: Specialized vector databases are designed for high-speed similarity search and can handle high-dimensional vectors efficiently, providing faster query responses in large datasets.\n",
      "2. **Scalability**: These databases are built to support scaling vector operations as data grows, often featuring distributed architectures and advanced indexing methods.\n",
      "3. **Advanced Features**: Offer advanced capabilities like approximate nearest neighbor search, which are essential for efficient vector similarity queries.\n",
      "4. **Purpose-Built**: Specifically optimized for vector data, providing potentially better performance and feature support for machine learning and AI applications.\n",
      "\n",
      "### Cons:\n",
      "1. **Complexity in Integration**: Introducing a new system into the stack can increase complexity, requiring additional effort for integration and data synchronization between systems.\n",
      "2. **Learning Curve**: The team may need to invest time in learning and adapting to a new database system, which can slow down initial development.\n",
      "3. **Lack of ACID Transactions**: Many vector databases may not support full ACID transactions, which could be a concern if consistency is crucial for certain operations.\n",
      "4. **Community and Support**: Being more specialized, these systems may have smaller communities and less comprehensive documentation compared to PostgreSQL.\n",
      "\n",
      "# Conclusion\n",
      "The choice between using PostgreSQL with pgvector and a specialized vector database depends on the specific requirements of the onboarding tool. If integration simplicity and transactional integrity are priorities, PostgreSQL with pgvector may be more suitable. However, if performance and scalability for vector operations are critical, a specialized vector database might be the better choice.\n",
      "\"\"\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# TWrite a prompt to research database options.\n",
    "db_research_prompt = \"\"\" \n",
    "You are an unbiased research assistant. Your task is to provide\n",
    "a balanced technical comparison for the software engineering team.\n",
    "\n",
    "Compare and contrast two technical options relating to our new \n",
    "hire onboarding tool: \n",
    "\n",
    "- ** Aproach 1**: Using PostgreSQL with the pgvector extension\n",
    "- ** Approach 2**: Using a specialized vector database like \n",
    "ChromaDB or FAISS\n",
    "\n",
    "For each approach, please list the pros and cons. \n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- Store the output in a variable titled `db_research_output`\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "enhanced_db_research_prompt = prompt_enhancer(db_research_prompt)\n",
    "print(\"enhanced_db_research_prompt:\", enhanced_db_research_prompt)\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 14:16:14,634 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_synthesis_prompt: <prompt>\n",
      "  <persona>\n",
      "    You are a Staff Software Engineer and seasoned Architectural Decision Record (ADR) author.  \n",
      "    You are meticulous, concise, and strictly adhere to Markdown formatting standards.\n",
      "  </persona>\n",
      "\n",
      "  <context>\n",
      "    1. You will receive:  \n",
      "       a. A Markdown ADR template.  \n",
      "       b. A research report comparing two database approaches (PostgreSQL + pgvector vs. a specialized vector DB).  \n",
      "    2. The engineering organization has already decided to adopt *Approach 1 (PostgreSQL with pgvector)*.  \n",
      "    3. Your goal is to create an ADR that formally documents this decision, grounding the “Context” section in the synthesized pros/cons from the research.\n",
      "  </context>\n",
      "\n",
      "  <instructions>\n",
      "    STEP 1 (Reasoning – internal):  \n",
      "      • Think step-by-step to extract the three most salient, decision-shaping points from the research (e.g., integration simplicity, ACID compliance, performance trade-offs).  \n",
      "      • Map these points to bullet items for the “Context” section.  \n",
      "      • Formulate a clear, single-sentence decision statement for the “Decision” section that explicitly names *Approach 1*.  \n",
      "      • Derive at least one positive and one negative consequence for the “Consequences” section.\n",
      "\n",
      "      (Do NOT reveal this reasoning; only output the final ADR.)\n",
      "\n",
      "    STEP 2 (Write ADR):  \n",
      "      • Populate every placeholder in the provided template.  \n",
      "      • Use concise, engineering-friendly language.  \n",
      "      • Set `Status:` to “Accepted”.  \n",
      "      • Title: “Database Selection for Vector-Enabled Onboarding Tool”.  \n",
      "      • Include exactly three context bullet points, one decision statement, one positive consequence, and one negative consequence.\n",
      "\n",
      "    STEP 3 (Output file wrapper):  \n",
      "      • Precede the ADR with a single line that specifies the save path:  \n",
      "        `Path: artifacts/adr_001_database_choice.md`  \n",
      "      • Then output the completed ADR inside a Markdown code block.\n",
      "\n",
      "  </instructions>\n",
      "\n",
      "  <examples>\n",
      "    <!-- Mini illustrative example for structure only -->\n",
      "    <example_input_snippet>\n",
      "      Template:\n",
      "      # &lt;TITLE&gt;\n",
      "      Status: &lt;STATUS&gt;\n",
      "      …\n",
      "    </example_input_snippet>\n",
      "\n",
      "    <example_output_snippet>\n",
      "Path: artifacts/example_adr.md\n",
      "```markdown\n",
      "# Example ADR Title\n",
      "Status: Accepted\n",
      "\n",
      "## Context\n",
      "* Point A\n",
      "* Point B\n",
      "* Point C\n",
      "\n",
      "## Decision\n",
      "We will use Technology X for reasons outlined above.\n",
      "\n",
      "## Consequences\n",
      "* Positive outcome\n",
      "* Negative trade-off\n",
      "```\n",
      "    </example_output_snippet>\n",
      "  </examples>\n",
      "\n",
      "  <output_format>\n",
      "    Your final reply must consist only of:  \n",
      "      1. The `Path:` line.  \n",
      "      2. One Markdown code block containing the filled-in ADR.  \n",
      "    No additional narration or commentary.\n",
      "  </output_format>\n",
      "</prompt>\n",
      "Path: artifacts/adr_001_database_choice.md\n",
      "```markdown\n",
      "# Database Selection for Vector-Enabled Onboarding Tool\n",
      "Status: Accepted\n",
      "\n",
      "## Context\n",
      "* PostgreSQL with pgvector offers seamless integration with existing systems, reducing the complexity and time required for deployment.\n",
      "* It maintains full ACID compliance, ensuring data integrity and reliability, which is critical for our operations.\n",
      "* While performance may not match that of specialized vector databases, the trade-off is acceptable given the benefits in integration and compliance.\n",
      "\n",
      "## Decision\n",
      "We will adopt Approach 1, using PostgreSQL with pgvector for our vector-enabled onboarding tool.\n",
      "\n",
      "## Consequences\n",
      "* Positive outcome: Simplified integration with existing infrastructure, leading to faster deployment and reduced maintenance overhead.\n",
      "* Negative trade-off: Potential performance limitations compared to a specialized vector database, which may affect scalability in high-demand scenarios.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "# TWrite a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"\n",
    "# Your prompt here. Remember to provide the research and the \n",
    "# template as context.\n",
    "\n",
    "You are a Staff Engineer. Based on the following markdown \n",
    "ADR template and the research output on database options,\n",
    "populate the ADR template. In this ADR template, formally \n",
    "document the decision to use Approach 1 (i.e.: Using \n",
    "PostgreSQL with pgvector) in the \"Decision\" section, and \n",
    "in the \"Context\" section justify the choice based on the \n",
    "synthesized pros and cons in the research output on database \n",
    "options:\n",
    "\n",
    "**ADR TEMPLATE**:\n",
    "{adr_template} \n",
    "\n",
    "**RESEARCH OUTPUT**:\n",
    "{db_research_output}\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- Save the final, completed ADR as \n",
    "artifacts/adr_001_database_choice.md.\n",
    "\"\"\"\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    enhanced_synthesis_prompt = prompt_enhancer(synthesis_prompt)\n",
    "    print(\"enhanced_synthesis_prompt:\", enhanced_synthesis_prompt)\n",
    "    final_adr = get_completion(enhanced_synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\",\n",
    "                  overwrite = True)\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
